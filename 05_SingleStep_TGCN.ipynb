{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# IMPORT LIBRARIES\n",
    "# ---------------------------------------------\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import TGCN \n",
    "from sklearn.neighbors import radius_neighbors_graph\n",
    "import torch_geometric_temporal.signal.static_graph_temporal_signal as SGTS\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# DEFINE MODEL ARCHITECTURE\n",
    "# - \n",
    "# - Relu \n",
    "# - Fully connected layer \n",
    "# ---------------------------------------------\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, forecast_len):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent1 = TGCN(node_features, 32, True)\n",
    "        self.linear1 = torch.nn.Linear(32, forecast_len) #(features from conv, output dimension)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent1(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear1(h)\n",
    "        return h\n",
    "\n",
    "    \n",
    "# ---------------------------------------------\n",
    "# LOAD DATA\n",
    "# **************** USER INPUT *****************\n",
    "# input the range of clusters \n",
    "# --------------------------------------------- \n",
    "cluster_id = 12\n",
    "\n",
    "data_path = '/Users/muneeza/Documents/GitHub/DATA_SMest/'\n",
    "\n",
    "# Set description variables - more details on variables from SWAT Manual at\n",
    "#Â https://swat.tamu.edu/media/69395/ch32_output.pdf\n",
    "sub_feat_names = ['AREA', # Area of HRU (km2)\n",
    "                  'PRECIP', # Total amount of precipitation falling on HRU during timestep (day) mm H20\n",
    "                  'ET', # Actual evapotranspiration (soil evaporation and plant transpiration) from the HRU during the time step (mm H20)\n",
    "                  'SW_END', # Soil water content (mm H20). Amount of water in the soil profile (at the end of the time period (day, month or year))\n",
    "                  'PERC', # Water that percolates past the root zone during the time step (mm H20) \n",
    "                  'GW_RCHG', # Recharge entering aquifers during the time step (mm H20)\n",
    "                  'DA_RCHG', # Deep aquifer recharge (mm H20)\n",
    "                  'REVAP', # Water in the shallow aquifer returning to the root zone in response to moisture deficit\n",
    "                  'SA_IRR', # Irrigation from shallow aquifer (mm H20)\n",
    "                  'DA_IRR', # Irrigation from deep aquifer (mm H20)\n",
    "                  'SA_ST', # Shallow aquifer storage\n",
    "                  'DA_ST', # Deep aquifer storage\n",
    "                  'WYLD', # Water yield (mm H20). Total amount of water leaving the HRU and entering main channel during the time step. \n",
    "                  'DAILYCN', # Average curve number for time period\n",
    "                  'TMP_AV', # Average daily air temperature \n",
    "                  'SOL_TMP', # Soil temperature (C)\n",
    "                  'SOLAR'] # Average daily solar radiation (MJ/m2). Average of daily solar radiation values for time period.\n",
    "            \n",
    "\n",
    "test_mse = []\n",
    "pers_mse = []\n",
    "rel_err = []\n",
    "for cluster in range(cluster_id):\n",
    "    # ---------------------------------------------\n",
    "    # READ PRE-PROCESSED DATA FOR THE CLUSTER \n",
    "    # this data contains a subset of informative features\n",
    "    # for a subsample of hrus for the given cluster\n",
    "    # data shape :  (timesteps, hrus, features )\n",
    "    # ---------------------------------------------\n",
    "    clstr_distance = np.load(data_path+'HRU_Clustering_results/'+'dist.in.cluster_'+str(cluster)+'.npy')\n",
    "    data = np.load(data_path+'sm_est_hru_data_clstr_'+str(cluster)+'.npy')\n",
    "\n",
    "    # Select id for target variable \n",
    "    target_id = sub_feat_names.index('SW_END')\n",
    "\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # TEST TRAIN SPLIT\n",
    "    # train : first 27 years\n",
    "    # test : year 27-34  \n",
    "    # discard end 2 years \n",
    "    # --------------------------------------------- \n",
    "    train_id_en = 27*12\n",
    "    test_id_en = 34*12 \n",
    "    X_train = data[0:train_id_en, :, :]\n",
    "    X_test = data[train_id_en:test_id_en, :, :]\n",
    "\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # NORMALIZE TEST AND TRAIN DATA SEPERATELY \n",
    "    # X (n_ts , sz, d) \n",
    "    # n_ts : number of time series (hrus)\n",
    "    # sz : size of time series (n time steps)\n",
    "    # d : dimension of data (n features)\n",
    "    # CAUTION !! data shape for normalization must be (hrus , timesteps , features )\n",
    "    # ---------------------------------------------\n",
    "    X_train = TimeSeriesScalerMinMax(value_range=(0,1)).fit_transform( np.transpose(X_train,(1,0,2)) )\n",
    "    X_test = TimeSeriesScalerMinMax(value_range=(0,1)).fit_transform( np.transpose(X_test,(1,0,2)) )\n",
    "    X_train = np.transpose(X_train, (1,0,2) ) # reshape back to original \n",
    "    X_test = np.transpose(X_test, (1,0,2) ) # reshape back to original \n",
    "\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # GENERATE LABELS FOR SEQUENCE PREDICTION \n",
    "    # X shape : (timesteps, hrus, features )\n",
    "    # Y shape : (timesteps, hrus, seq_len )\n",
    "    # --------------------------------------------- \n",
    "    seq_len = 1\n",
    "    n_feat = len(sub_feat_names)\n",
    "    n_hrus = X_train.shape[1]\n",
    "    test_len = X_test.shape[0]\n",
    "\n",
    "    Y_train = np.zeros((train_id_en - seq_len , n_hrus, seq_len))\n",
    "    Y_test = np.zeros((test_len - seq_len , n_hrus, seq_len))\n",
    "\n",
    "    # For data X at time T, the prediction Y is\n",
    "    # Y[T] = X[T+1 : T+seq_len]\n",
    "    for i in range(train_id_en - seq_len):\n",
    "        Y_train[i, : , :] = X_train[i+1:i+1+seq_len  , : , target_id ].T\n",
    "    for i in range(1 , test_len - seq_len):    \n",
    "        Y_test[i-1, : , :] = X_test[i:i+seq_len , : , target_id].T\n",
    "\n",
    "    # Remove the last seq_len values from X \n",
    "    # since their corresponding forecast sequences \n",
    "    # arnt available.      \n",
    "    X_train = X_train[0:train_id_en-seq_len , : , :  ]\n",
    "    X_test = X_test[0:test_len-seq_len , : , : ]\n",
    "\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # GENERATE STATIC GRAPH STRUCTURE\n",
    "    # ---------------------------------------------\n",
    "    adj_csr = radius_neighbors_graph( clstr_distance, 1, include_self = True)\n",
    "\n",
    "    # Adjacency matrix to edge list for PyG Data structure \n",
    "    adj_coo = np.transpose(adj_csr).tocoo()\n",
    "    row = torch.tensor(adj_coo.row)\n",
    "    col = torch.tensor(adj_coo.col) \n",
    "    edge_attr = torch.tensor(adj_coo.data).type(torch.float)\n",
    "    edge_index = torch.stack([row, col], dim=0).type(torch.long)\n",
    "\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # GENERATE TEMPORAL GRAPH DATA\n",
    "    # Shape for graph data :  (timeseries, hrus , features )\n",
    "    # ---------------------------------------------\n",
    "    train_dataset = SGTS.StaticGraphTemporalSignal(edge_index=edge_index, edge_weight=edge_attr, features=X_train, targets=Y_train)\n",
    "    test_dataset = SGTS.StaticGraphTemporalSignal(edge_index=edge_index, edge_weight=edge_attr, features=X_test, targets=Y_test)\n",
    "\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # TRAIN MODEL \n",
    "    # Hyperparameters: \n",
    "    # - learning rate (lr) = 0.01\n",
    "    # - weights initialization \n",
    "    # - epochs - early stopping \n",
    "    # ---------------------------------------------\n",
    "    epochs = 10\n",
    "    model = RecurrentGCN(node_features = n_feat, forecast_len = seq_len )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    model.train()\n",
    "    hist = []\n",
    "    for ep in tqdm(range(epochs)):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "            cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "        cost = cost / (time+1)\n",
    "        hist.append(cost.item())\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # MODEL EVALUATION\n",
    "    # ---------------------------------------------\n",
    "    model.eval()\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    cost = cost / (time+1)\n",
    "    test_mse.append(cost.item())\n",
    "    print(\"Clustering + TGCN MSE: {:.3f}\".format(test_mse[cluster]))\n",
    "\n",
    "\n",
    "print(\"Clustering + TGCN Mean MSE on test data: {:.4f}\".format( np.mean(np.array(test_mse)) ))\n",
    "print(\"Clustering + TGCN Var MSE on test data: {:.4f}\".format( np.var(np.array(test_mse)) ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f5b3ae0745328dcc61aefa536325bd90100aa39ad9e0c20a14dd1c1a401e940"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
