{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# IMPORT LIBRARIES\n",
    "# ---------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "data_path = '/Users/muneeza/Documents/GitHub/DATA_SWAT/hru_region02_np_arr'\n",
    "save_dir = '/Users/muneeza/Documents/GitHub/DATA_SMest/HRU_TGCN_sub/'\n",
    "\n",
    "# ---------------------------------------------\n",
    "# LOAD FEATURE NAMES AND DESCRIPTIONS\n",
    "# Feature description is a dictionary object that \n",
    "# contains feature_name: feature definition pairs \n",
    "# based on SWAT IO documentation\n",
    "# --------------------------------------------\n",
    "with open('/Users/muneeza/Documents/GitHub/GNNs_PrecisionAgriculture/SWAT Data reader/SWAT_feat_names.pkl', 'rb') as f:\n",
    "    feat_names = pickle.load(f)\n",
    "with open('/Users/muneeza/Documents/GitHub/GNNs_PrecisionAgriculture/SWAT Data reader/SWAT_feat_names.pkl', 'rb') as f:\n",
    "    feat_names = pickle.load(f)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# SUBSET OF FEATURES FOR SM PREDICTION\n",
    "# **************** USER INPUT *****************\n",
    "# Define features used for estimating soil moisture\n",
    "# --------------------------------------------- \n",
    "sub_feat_names = ['AREA', 'PRECIP' , 'ET', 'SW_END', 'PERC', 'GW_RCHG', 'DA_RCHG', 'REVAP', 'SA_IRR', 'DA_IRR', 'SA_ST', 'DA_ST',\n",
    "                 'WYLD', 'DAILYCN', 'TMP_AV', 'SOL_TMP', 'SOLAR']\n",
    "\n",
    "names_list = os.listdir(data_path)\n",
    "if '.DS_Store' in names_list: names_list.remove('.DS_Store')\n",
    "if 'README' in names_list: names_list.remove('README')\n",
    "    \n",
    "    \n",
    "# ---------------------------------------------\n",
    "# INDEPENDENT HRU FILES\n",
    "# Instead of HRUs clumped together in watersheds\n",
    "# associate universal IDs with the hrus for tracability\n",
    "# and save as independent files.\n",
    "# --------------------------------------------- \n",
    "clustering_feature_names = feat_names[5:]\n",
    "n_feat = len(sub_feat_names) \n",
    "n_tstep = 38*12\n",
    "\n",
    "for name in names_list:\n",
    "    features = np.load(data_path+'/'+name)\n",
    "\n",
    "    # Delete annual summary (over a single year)\n",
    "    # Delete simulation summary  (over 38 years)    \n",
    "    df = pd.DataFrame(features)\n",
    "    df.columns= feat_names[5:86]    \n",
    "    df.drop(df[df.MON > 12].index, inplace=True)\n",
    "    n_hru = df.MON.ne(1).idxmax()\n",
    "\n",
    "    # select a subset of features \n",
    "    sub_df = df[sub_feat_names]\n",
    "\n",
    "    # Rearrange data so data is in the format ( monthly time step, hrus, features) \n",
    "    num_features = sub_df.to_numpy()\n",
    "    num_features = num_features.reshape(n_tstep, n_hru, n_feat )  \n",
    "\n",
    "    # Save the data for each hru (time step , features)\n",
    "    for i in range(n_hru):                                 \n",
    "        np.save(save_dir+name.split('_')[0]+'.'+str(n_hru)+'.'+str(i), num_features[:,i,:])\n",
    "        \n",
    "\n",
    "# FROM 04_ SUBSAMPLING\n",
    "# Define data paths and size\n",
    "# Load results from clustering\n",
    "\n",
    "data_path = '/Users/muneeza/Documents/GitHub/DATA_SMest/HRU_Clustering_results/'\n",
    "\n",
    "X_train_norm = np.load(data_path+'norm_hru_clustering_data.npy')\n",
    "dist = np.load(data_path+'hru_cluster_distance.npy')\n",
    "labels = np.load(data_path+'hru_cluster_labels.npy')\n",
    "\n",
    "with open(data_path+'names_list_clustering.pkl', 'rb') as f:\n",
    "    names_list = pickle.load(f)\n",
    "\n",
    "n_hrus = np.array([x.split('.')[-2] for x in names_list]).astype(int)\n",
    "hrus_total = np.sum(n_hrus)\n",
    "\n",
    "mean_t = np.mean(X_train_norm,0)\n",
    "var_t = np.var(X_train_norm,0)\n",
    "\n",
    "# save new names list with hru ids \n",
    "hru_names_list = []\n",
    "for i, name in enumerate(names_list):\n",
    "    for j in range(n_hrus[i]):\n",
    "        hru_names_list.append(name.split('_')[0]+'.'+str(n_hrus[i])+'.'+str(j))\n",
    "\n",
    "pickle.dump(names_list, open(data_path+'hru_names_list_clustering.pkl', 'wb'))\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Load a subset of hrus as save as anumpy array\n",
    "# Based on results from 05_Subsampling hrus\n",
    "# --------------------------------------------- \n",
    "\n",
    "with open(data_path+'names_list_sub_clusterwise.pkl', 'rb') as f: names_list = pickle.load(f)\n",
    "\n",
    "# Save Training Data for transfer to CCC\n",
    "for i in range(12):\n",
    "    n_hrus = len(names_list[i])\n",
    "\n",
    "    # Read hru data  \n",
    "    # !!! Make sure data is in format (timeseries, hrus , features)\n",
    "    data = np.zeros((n_tstep, n_hrus , n_feat))\n",
    "    for j, name in enumerate(names_list[i]):\n",
    "        data[:,j,:] = np.load(save_dir+name+'.npy') # (tstep , features)\n",
    "        \n",
    "    np.save('/Users/Documents/GitHub/DATA_SMest/sm_est_hru_data_clstr_'+str(i),data)\n",
    "    \n",
    "    \n",
    "# ---------------------------------------------\n",
    "# VISUALIZE GRAPH FROM CLUSTER \n",
    "# Run at your own risk - Very slow for large graphs\n",
    "# you have been warned !! \n",
    "# --------------------------------------------- \n",
    "\n",
    "# import networkx as nx\n",
    "# from torch_geometric.utils.convert import to_networkx\n",
    "# from sklearn.neighbors import radius_neighbors_graph\n",
    "\n",
    "# cluster_id = 6\n",
    "# clstr_distance = np.load('/Users/muneeza/Documents/GitHub/DATA_SMest/HRU_Clustering_results/'+'dist.in.cluster_'+str(cluster_id)+'.npy')\n",
    "# adj_csr = radius_neighbors_graph( clstr_distance, 1, include_self = True)\n",
    "\n",
    "# G = nx.Graph(adj_csr)\n",
    "# nx.draw(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
